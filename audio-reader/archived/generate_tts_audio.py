#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Google Cloud Text-to-Speech API ã‚’ä½¿ç”¨ã—ãŸéŸ³å£°ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import io
from google.cloud import texttospeech
from pathlib import Path

# Windowsã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œå¯¾ç­–
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# ç’°å¢ƒå¤‰æ•°ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã‚’è¨­å®š
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'service-account-key.json'

def split_text_by_bytes(text: str, max_bytes: int = 4000) -> list:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒã‚¤ãƒˆæ•°åˆ¶é™ã«åŸºã¥ã„ã¦åˆ†å‰²
    
    Args:
        text: åˆ†å‰²ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        max_bytes: æœ€å¤§ãƒã‚¤ãƒˆæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4000ã€APIåˆ¶é™ã¯5000ï¼‰
    
    Returns:
        åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    chunks = []
    current_chunk = ""
    
    for line in text.split('\n'):
        test_chunk = current_chunk + line + '\n'
        if len(test_chunk.encode('utf-8')) > max_bytes:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = line + '\n'
        else:
            current_chunk = test_chunk
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def generate_audio(text: str, output_path: str, voice_name: str = 'ja-JP-Neural2-C'):
    """
    Google Cloud TTS APIã§éŸ³å£°ã‚’ç”Ÿæˆ
    
    Args:
        text: èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆMP3ï¼‰
        voice_name: éŸ³å£°å
            - ja-JP-Neural2-B: ç”·æ€§å£°
            - ja-JP-Neural2-C: å¥³æ€§å£°
            - ja-JP-Neural2-D: ç”·æ€§å£°ï¼ˆä½éŸ³ï¼‰
    """
    from pydub import AudioSegment
    
    client = texttospeech.TextToSpeechClient()
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    chunks = split_text_by_bytes(text, max_bytes=4000)
    print(f'   ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²: {len(chunks)} ãƒãƒ£ãƒ³ã‚¯')
    
    audio_segments = []
    
    for i, chunk in enumerate(chunks, 1):
        print(f'   ãƒãƒ£ãƒ³ã‚¯ {i}/{len(chunks)} å‡¦ç†ä¸­... ({len(chunk)} chars)')
        
        # éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š
        synthesis_input = texttospeech.SynthesisInput(text=chunk)
        
        # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        voice = texttospeech.VoiceSelectionParams(
            language_code="ja-JP",
            name=voice_name
        )
        
        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¨­å®šï¼ˆMP3å½¢å¼ï¼‰
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=1.0  # è©±é€Ÿï¼ˆ0.25ï½4.0ï¼‰
        )
        
        # éŸ³å£°åˆæˆå®Ÿè¡Œ
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        # AudioSegmentä½œæˆ
        audio_segment = AudioSegment.from_mp3(
            io.BytesIO(response.audio_content)
        )
        audio_segments.append(audio_segment)
    
    # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
    combined = audio_segments[0]
    for segment in audio_segments[1:]:
        combined += segment
    
    # MP3ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    combined.export(output_path, format="mp3")
    
    print(f'âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {output_path}')
    print(f'   æ–‡å­—æ•°: {len(text)} chars')
    print(f'   éŸ³å£°: {voice_name}')

def generate_article_audio(article_slug: str):
    """
    è¨˜äº‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆç”·æ€§å£°ãƒ»å¥³æ€§å£°ï¼‰
    
    Args:
        article_slug: è¨˜äº‹ã®ã‚¹ãƒ©ãƒƒã‚°å
    """
    # è¨˜äº‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® articles/ ã‚’å‚ç…§ï¼‰
    article_path = Path(__file__).parent.parent / 'articles' / f'{article_slug}.md'
    if not article_path.exists():
        print(f'âŒ ã‚¨ãƒ©ãƒ¼: è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {article_path}')
        return
    
    with open(article_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # éŸ³å£°å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    audio_dir = Path(f'audio/{article_slug}')
    audio_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”·æ€§å£°ç”Ÿæˆ
    male_path = audio_dir / 'article_ja-male.mp3'
    print(f'\nğŸ™ï¸ ç”·æ€§å£°ã‚’ç”Ÿæˆä¸­...')
    generate_audio(content, str(male_path), voice_name='ja-JP-Neural2-B')
    
    # å¥³æ€§å£°ç”Ÿæˆ
    female_path = audio_dir / 'article_ja-female.mp3'
    print(f'\nğŸ™ï¸ å¥³æ€§å£°ã‚’ç”Ÿæˆä¸­...')
    generate_audio(content, str(female_path), voice_name='ja-JP-Neural2-C')
    
    print(f'\nâœ… è¨˜äº‹ã®éŸ³å£°ç”Ÿæˆå®Œäº†: {article_slug}')

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print('ä½¿ç”¨æ–¹æ³•: python generate_tts_audio.py <article-slug>')
        print('ä¾‹: python generate_tts_audio.py affinity-3-free-canva-ai-strategy-2025')
        sys.exit(1)
    
    article_slug = sys.argv[1]
    generate_article_audio(article_slug)
