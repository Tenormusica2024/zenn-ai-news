---
title: "AIエージェント、7割失敗してるってマジか"
emoji: "🤖"
type: "tech"
topics: ["AI", "エージェント", "ChatGPT", "機械学習"]
published: false
---

## 参照元
AI agents wrong ~70% of time: Carnegie Mellon study - The Register
https://www.theregister.com/2025/06/29/ai_agents_fail_a_lot/

## ベンチマークの結果がエグい

Carnegie Mellon の研究チームが「TheAgentCompany」っていうベンチマークを作って、主要な AI エージェントをオフィスワークのタスクで評価したんですが、結果が...まあ、正直厳しいです。

一番成績が良かった Google の Gemini 2.5 Pro でも、タスクの70%で失敗。部分的に完了したケースを含めても失敗率61.7%。他のモデルはもっと悲惨で、OpenAI の GPT-4o は失敗率91.4%、Meta の Llama-3.1-405b は92.6%、Amazon の Nova-Pro-v1 に至っては98.3%が失敗。

これ見た時、「マジか」って思いました。前に CRM システムで AI エージェント試した時も、目標達成率が55%くらいで「まあこんなもんか」と思ってたんですが、業界全体で見ても似たような状況なんですね。

## 2025年は「エージェントの年」じゃなかったのか？

業界では2025年を「AI エージェントの年」って呼んでて、OpenAI も7月に ChatGPT Agent をローンチしたし、AgentKit っていう開発者向けツールキットも提供開始しました。AI エージェント市場は2024年の51億ドルから2030年には471億ドルに成長するって予測も出てます（CAGR 44.8%）。

で、実際に OpenAI の ChatGPT Agent（Pro/Plus/Team ユーザー向け）は、カレンダー分析、プレゼン作成、ウェブサイト操作なんかができるって謳ってます。エキスパートレベルの推論ベンチマークで41.6%のスコア、タスク成功率80%（実装による）とか数字も出てて、一見良さそうに見えるんです。

でも実際の使用感は...X（旧 Twitter）でインフルエンサーが「マジで聞きたいんだけど、ChatGPT Agent 使ってる人いる？どんなユースケース？自分には（限定的な）機能に合うユースケースが見つからないんだが」って投稿してて、これが結構 RT されてました。

## エラーが積み重なる問題

ある開発者がエージェントシステムを作ってて気づいたことを書いてたんですが、「エラーの積み重ねが自律型のマルチステップワークフローを数学的に不可能にしてる」って指摘してました。

具体的には、1ステップあたり95%の信頼性があっても、20ステップ経ると成功率は36%まで落ちる。でも本番環境で使うには99.9%以上の信頼性が必要。これ、確かにそうだなと。

前にワークフローオートメーションツールで似たような経験したことがあります。単体のタスクは問題なく動くんだけど、5-6個のタスクを連鎖させると、どこかでコケる。で、デバッグに時間かかって、結局手動でやった方が早かったっていう...あるあるですよね。

## IBM も懐疑的

IBM の研究者も「2025年がエージェントの年になるかどうかは、定義次第だし、AI エージェントがどんな価値をもたらすかによる」って慎重な姿勢を示してます。

MIT のレポート「The Gen AI Divide: State of AI in Business 2025」では、生成 AI プロジェクトの95%が失敗してるって結果が出てて、資本の無駄遣い、時間の浪費、AI への懐疑が増大してるとのこと。

Gartner の予測だと、2027年までに企業が開始した AI エージェントプロジェクトの40%以上がキャンセルされるって言ってます。理由は制御不能なコスト、曖昧なビジネス価値、予測不可能なセキュリティリスク。

これ見て思ったんですが、前にブロックチェーン案件でも似たような状況ありましたよね。2017-2018年頃、「うちもブロックチェーン導入しよう」って企業が増えたけど、結局多くが「何に使うの？」ってなって頓挫した。今の AI エージェントも、同じ道を辿らないといいんですが。

## じゃあ AgentKit は何を解決するのか

OpenAI が提供開始した AgentKit には以下の機能があります：

- **Agent Builder**: ドラッグ&ドロップでロジックを組めるビジュアルキャンバス
- **ChatKit**: カスタマイズ可能なチャット体験の埋め込み
- **Connector Registry**: 統合管理用のレジストリ

ノーコードでマルチエージェントワークフローを構築できるってのは、確かに便利そうです。Canva が「サポートエージェントの構築で2週間以上の時間を節約できた」って報告してるし、一定の効果はあるんでしょう。

でも、ここで気になるのは「2週間節約」って言ってるけど、実際のエージェントの成功率は？運用コストは？メンテナンスは？っていう部分が見えてこないんですよね。

前にノーコードツールで別のシステム作った時、最初は確かに早かったんですが、カスタマイズしようとすると逆に時間かかったり、スケールした時にパフォーマンス問題が出たりして...結局、部分的にコード書き直しました。AgentKit もそうならないといいんですが。

## DevDay 2025 での反応

OpenAI DevDay 2025（10月開催）では、開発者や企業、技術者が「興奮と懐疑と大量の疑問」を抱えて帰ったらしいです。

発表された数字は確かに印象的でした：
- 週間8億ユーザー
- 400万人の開発者
- 毎分80億トークン処理

でも、レビューを見ると「ChatGPT Agent は印象的だけど不完全。魔法のような万能アシスタントにはまだなってない。でも近づいてる」っていう温度感。

Gary Marcus（AI 懐疑派で知られる研究者）は「AI エージェントは、これまでのところ、ほぼ不発」っていうタイトルの記事を書いてて、まあ、辛辣ですけど、現状を見ると完全には否定できないんですよね。

## 実用化のハードルは高い

結局のところ、AI エージェントが実用レベルに達するには、まだいくつかハードルがあります：

1. **信頼性の向上**: 70%の失敗率では本番環境で使えない
2. **エラーハンドリング**: マルチステップワークフローでのエラー積み重ね問題
3. **コスト管理**: Gartner が指摘する「制御不能なコスト」
4. **セキュリティ**: 予測不可能なリスクへの対処
5. **明確なユースケース**: 「何に使うのか」がまだ見えてない

前に、自動化ツールを導入しようとした時、結局「このタスクは自動化する価値あるか？」って精査したら、実は手動でやった方が早いケースが多かったんです。AI エージェントも、同じような精査が必要なんじゃないかと思ってます。

## 期待と現実のギャップ

市場予測では2030年に471億ドル、企業の85%が2025年末までにエージェントを導入予定、とか景気のいい数字が並んでます。でも、Gartner は40%以上がキャンセルされると予測してるし、MIT は95%が失敗してるって報告してる。

このギャップ、どう解釈すればいいんでしょう。投資家は盛り上がってるけど、現場の開発者は冷静に「まだ早い」って見てる、ってことなのかもしれません。

前にブロックチェーン案件の時もそうでしたが、技術が先行して、実際のユースケースが後からついてくる（または、ついてこない）パターンって多いんですよね。AI エージェントが本当に実用化されるのか、それともブームだけで終わるのか。もうちょっと様子を見る必要がありそうです。

個人的には、完全自律型のエージェントじゃなくて、人間のアシスタント的な立ち位置（半自動化）の方が現実的だと思ってます。100%任せるんじゃなくて、80%くらい自動化して、最後は人間が確認する、みたいな。そういう使い方なら、70%の失敗率でも、うまく運用できるかもしれません。
