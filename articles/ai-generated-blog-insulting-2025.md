---
title: "AI生成ブログが侮辱的と言われる理由 - Hacker News 860ポイントの議論"
emoji: "✍️"
type: "tech"
topics: ["AI", "コンテンツ生成", "ブログ", "執筆"]
published: false
---

## 参照元
It's insulting to read your AI-generated blog post - pablog
https://blog.pabloecortez.com/its-insulting-to-read-your-ai-generated-blog-post/

It's insulting to read your AI-generated blog post | Hacker News
https://news.ycombinator.com/item?id=45722069

## Hacker News 860ポイント獲得の批判記事

Pablo Cortezが投稿した「It's insulting to read your AI-generated blog post」がHacker Newsで860ポイント、419コメントを集めています。

記事の核心は、AI生成ブログを読むことが読者に対する失礼だという主張です。「lexical bingo machine」（語彙ビンゴマシン）が吐き出したようなものを読ませるのは無神経だと批判しています。

開発者コミュニティでこれだけの注目を集めているのは、AI生成コンテンツに対する疲労感が技術者層でピークに達している証拠かもしれません。

## 「感情がないコンテンツ」という本質的問題

Pablo Cortezの主張で興味深いのは、「The best thoughts are the ones that have been felt」という指摘です。AI生成コンテンツは、人間の経験、感情、ユーモアを欠いているため、表面的にはまともな文章でも「魂がない」という印象を与えます。

特に技術ブログでは、書き手の試行錯誤、失敗談、「3日溶けた」みたいな生々しい体験が読者との信頼関係を作ります。AIがいくら「効率的に情報を整理」しても、この人間臭さは再現できません。

コメント欄でも「Code review is one of the places where experience is transferred」という指摘がありました。技術的な知識だけでなく、経験からくる文脈的理解が失われることへの懸念です。

## AI生成コンテンツの実態データ（2025年）

AI生成コンテンツに関する調査データを見ると、状況がより具体的に見えてきます。

**Google検索での実態:**
- 86%の記事は人間が書いたもの
- AI生成記事は14%
- AI生成記事は人間の記事より検索順位が低い傾向

**信頼性の問題:**
- AI生成ニュースは人間が書いた記事と比べて「いいね」が少ない
- 信頼性の欠如が主な原因（真正性の問題ではない）

**検出ツールの限界:**
- AI検出ツールは信頼性が低い
- 人間が書いた記事をAI生成と誤判定することが頻繁

この数字を見ると、AI生成コンテンツは「効率的」かもしれないけど、読者からの評価は明らかに低いです。

## コミュニティの分断 - Reddit・Hacker Newsの反応

Hacker Newsのコメント欄は、AI生成コンテンツに対する賛否両論が入り混じっています。

**批判派の主張:**
- 「低努力なコンテンツで読者の時間を無駄にしている」
- 「学習機会を奪う - 書くことで理解が深まるのに」
- 「個人のボイスが消え、全部同じトーンになる」

**擁護派の視点:**
- ドラフト作成には有用
- ボイラープレートコンテンツの効率化
- 構造的なサポートとして使う分には問題ない

興味深いのは、ほとんどの開発者が「AI補助はOK、完全AI生成はNG」というスタンスです。人間がレビュー・修正する前提なら受け入れられるけど、AIに丸投げは避けるべきという線引きです。

**Redditモデレーターの懸念:**
Cornellの研究によると、Redditのモデレーターは「AI生成コンテンツが3つの脅威をもたらす」と指摘しています:
1. コンテンツ品質の低下
2. コミュニティの社会的ダイナミクスの破壊
3. ガバナンスの困難化

特に「authenticity」を重視するコミュニティでは、AI生成コンテンツへの反発が強いです。

## 完璧すぎる文章がバレる理由

AI生成コンテンツが見抜かれる理由は、皮肉にも「完璧すぎる」ことです。

uhyo氏のAI記事生成プロジェクトで指摘されていますが、人間の文章には以下の特徴があります:

**人間らしさのマーカー:**
- 試行錯誤の痕跡（「最初これ試したけどダメで...」）
- 突然の余談（戻ってこないこともある）
- 説明の深さが不均一（興味のある部分だけ詳しい）
- 未解決の疑問（「この辺まだ確認してないけど」）
- 自己訂正（「いや待って、これ違うわ」）

AI生成コンテンツは、これらを「戦略的」に配置しようとするため、逆に不自然になります。セクションごとに均等に「不完全性」を入れるとか、すべてのエピソードにハッピーエンディングを用意するとか。

実際の人間は、興味ない部分は雑に説明して、気になる部分だけ10段落使って深堀りします。この「ムラ」がないと、読者は「これAIっぽいな」と感じます。

## 技術ブログでのAI活用ジレンマ

前に技術記事をAIに下書きさせたことがあります。確かに構成はしっかりしてるし、文法も完璧。ただ、自分の言葉で書き直すのに結局同じくらい時間がかかりました。

なぜなら、「この実装で詰まった」とか「3時間デバッグした結果、タイポだった」みたいな、恥ずかしいけど共感される体験をAIは生成できないからです。

AI生成の技術記事は「教科書的」になりがちです。「まず〇〇について説明します」「次に△△を見ていきましょう」みたいな教育的な足場が多すぎて、仲間との会話っぽさがゼロ。

技術ブログの読者は、綺麗にまとまった情報だけじゃなくて、「実際にやってみたらこうだった」という生々しさを求めてます。それがないと、公式ドキュメント読んだ方が早い。

## 「執筆は学習」という視点の喪失

Pablo Cortezの記事で重要なのは、「失敗や間違いから学ぶことが人間らしさである」という指摘です。

AI生成に頼ると、自分で考えて言語化するプロセスが失われます。技術ブログを書くことで、曖昧だった理解が明確になったり、実装の矛盾に気づいたりする経験は、開発者にとって重要な学習機会です。

Hacker Newsのコメントでも「Writing, even technical writing, is an art. Art comes from experience」という意見がありました。コードレビューと同じで、執筆を通じて経験が伝達されるという考え方です。

AI生成コンテンツが増えると、この「執筆を通じた学習」が業界全体で減少するリスクがあります。効率化と引き換えに、次世代の技術者が深い理解を得る機会を奪っている可能性。

## AI生成の見分け方は結局「違和感」

AI検出ツールは精度が低いですが、人間の直感は意外と正確です。

読んでいて「なんか機械的だな」と感じる瞬間があります。具体的には:
- すべてのセクションが同じ長さ
- 「パターン1、パターン2、パターン3」みたいな列挙が多い
- 話の展開が線形すぎる（唐突なジャンプがない）
- 結論で全部きれいにまとまりすぎる

人間の文章は、もっと雑然としてます。急に話題が飛んだり、「そういえば」で始まる余談が主題に戻らなかったり、最後に新しい疑問を投げかけて終わったり。

Pablo Cortezが「insulting」と表現したのは、この違和感を感じた読者が「時間を無駄にした」と感じる瞬間への批判です。

## 真正性の経済学 - コストと価値のトレードオフ

Santa Clara大学のMarkkula Center for Applied Ethicsの記事「Authenticity In The AI Content Era Will Not Come Cheap」は、本質的な問題を指摘しています。

AI時代における真正性（authenticity）は、今後ますます希少価値になります。誰でもAIでコンテンツを量産できる時代に、「本物の人間が書いた」ことの価値が上がる。

ただ、人間が書くには時間とコストがかかります。Pablo Cortezの記事が共感を集めているのは、この「コスト削減のために読者の時間を犠牲にしている」という構図への反発です。

技術ブログの文脈で言うと、AI生成で効率化した分、書き手は楽になるけど、読み手は「また同じトーンの無味乾燥な記事か」と離脱します。結局、エンゲージメントが下がってビジネス的にもマイナス。

## 86%は人間が書いているという現実

2025年のデータで興味深いのは、Google検索で上位表示される記事の86%が依然として人間によるものだという点です。

AI生成記事は14%しかなく、しかも順位が低い傾向。これは、Googleのアルゴリズムがまだ「人間らしさ」を評価している証拠かもしれません。

前にSEO目的でAI記事を量産する実験をしたことがあります（個人ブログで）。確かに記事数は増えたけど、滞在時間とリピート率が壊滅的でした。読者は1記事読んで「ああ、AI記事のサイトか」と判断して離脱。

AI生成コンテンツの「効率」は、短期的な生産性向上には寄与するけど、長期的な読者との関係構築には逆効果です。Pablo Cortezが「insulting」と表現したのは、この読者軽視への怒りだと思います。

## AIに任せるべき部分、人間が書くべき部分

AI生成コンテンツ全否定ではなく、使い分けの議論が必要です。

**AIに任せても良い部分:**
- ドキュメントの初期ドラフト
- 定型的なAPI仕様書
- 構造化されたデータの説明
- 既存情報の要約

**人間が書くべき部分:**
- 個人の経験に基づく洞察
- コミュニティとの対話
- 試行錯誤のプロセス
- 主観的な評価・推奨

Hacker Newsの議論でも、「AIは starting point として使うべき」という意見が多数です。完全にAI任せではなく、人間がレビュー・修正・個性を加えることが前提。

ただ、現実には「AIが生成したものをそのまま公開」するケースが増えているから、Pablo Cortezみたいな批判が出るわけです。

## Reddit・Hacker Newsが重視する「authenticity」

技術コミュニティ、特にReddit・Hacker Newsは「authenticity」を非常に重視します。

AI生成コンテンツへの反発が強いのは、これらのプラットフォームが「本物の議論」「生の経験」を価値として掲げているからです。

Cornellの研究でRedditモデレーターが「AI生成コンテンツは社会的ダイナミクスを破壊する」と述べていますが、これは単なる品質問題じゃなくて、コミュニティの存在意義に関わる問題です。

「誰かがAIに投げて生成した記事」を読むために、Hacker NewsやRedditに来る人はいません。リアルな開発者の経験、失敗談、「これやばいんじゃない？」みたいな率直な意見を求めてます。

## AIツール自体は悪くない、使い方の問題

誤解を避けるために言うと、AIツール自体は素晴らしいです。Claude Code、GitHub Copilot、ChatGPTは開発効率を劇的に上げました。

問題は、「AI生成をそのまま公開する」という使い方です。

前にGitHub Copilotでコード書いてて、提案されたコードが動くけど「なんでこれで動くの？」と理解できなかった経験があります。その時、Copilotの提案を採用せず、自分で書き直しました。結果、時間はかかったけど、理解が深まった。

技術ブログも同じです。AIに下書きさせるのは良いけど、最終的に「自分の言葉」に変換しないと、読者との genuine な関係は築けません。

Pablo Cortezの批判は、「AI使うな」じゃなくて「AIに丸投げして読者に失礼なもの押し付けるな」ということです。

## 今後の展望 - AI生成コンテンツの淘汰

86%が人間の記事、14%がAI生成という現状は、今後どう変化するでしょうか。

個人的には、AI生成コンテンツは「低品質コンテンツ」として淘汰されていくと思います。理由は:

1. 読者が見抜ける（「違和感」で判断）
2. エンゲージメントが低い（滞在時間、リピート率）
3. SEOアルゴリズムが人間コンテンツを優遇
4. コミュニティが排除する（Reddit・Hacker News等）

ただ、「人間とAIの協働」という形は残るでしょう。AI生成の効率性と、人間の個性・経験を組み合わせたハイブリッドアプローチです。

Hacker Newsのコメントでも「AI should be a starting point, not a replacement」という意見が主流でした。これが現実的な落としどころだと思います。

完全AI生成コンテンツは、「lexical bingo machine」として読者から軽蔑され、人間の手が入ったコンテンツが価値を持つ。Pablo Cortezの記事が860ポイント獲得したのは、この価値観が技術コミュニティで共有されている証拠です。
