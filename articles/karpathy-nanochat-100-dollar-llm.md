---
title: "Karpathyが$100でChatGPT作る8000行コード公開 - nanochat"
emoji: "💰"
type: "tech"
topics: ["AI", "機械学習", "LLM"]
published: false
---

## 元記事
NanoChat – The best ChatGPT that $100 can buy - Hacker News
https://news.ycombinator.com/item?id=45569350

GitHub Repository by Andrej Karpathy
https://github.com/karpathy/nanochat

## $100でChatGPTクローンが作れる時代

Andrej Karpathy（OpenAI創設メンバー、元Tesla AI部門ディレクター）が10月13日に公開した「nanochat」が、開発者コミュニティで大きな反響を呼んでいます（Hacker Newsで903ポイント獲得）。

反響の理由は3つあります。

**1. LLM訓練の全工程を8000行で実装**  
トークン化から推論、Web UIまで含む「フルスタック」実装を、たった8000行のミニマルなコードで実現。前作nanoGPTが事前訓練のみだったのに対し、nanochatは完全な訓練パイプラインです。

**2. $100・4時間という具体的な数字**  
8xH100ノードで4時間訓練すると約$100。「ChatGPTクローンを作るのにいくらかかるのか」という疑問に、明確な答えを示しました。

**3. 教育ツールとしての設計**  
Karpathyが開発中のLLM101nコースのキャップストーンプロジェクトとして設計。「basically entirely hand-written」とKarpathy自身が述べるように、AIコーディングツールをほぼ使わず、学習目的で一から書かれています。

## 技術仕様と訓練コスト

具体的な数字を見てみます。

8xH100ノード（各80GB VRAM）で4時間訓練すると約$100。時間単価は$24/時なので、計算は合います。コメント欄では「80GB VRAMのGPUは1時間$1-3」という指摘もあり、プロバイダーによって価格差がありそうです。

訓練されるモデルは561Mパラメータ。GPT-2（1.5B）より小さいですが、「幼稚園児と話してる感じ」とKarpathy自身が表現する程度には動きます。12時間訓練（約$300）でGPT-2のCOREベンチマークを超え、42時間（約$1000）で簡単な数学・コーディング問題が解けるレベルになるとのこと。

使用データセットはFineWeb-eduなど。コード自体はPyTorchベースで、トークナイザーだけRustです。

## 開発者が注目している実装の現実

Hacker Newsのコメントで目立つのは「教育ツールとしての価値」です。

Karpathyが開発中のLLM101nコースのキャップストーンプロジェクトになる予定で、LLM訓練の全工程を学ぶための最小実装として設計されています。「basically entirely hand-written」とKarpathy自身が言っているように、AIコーディングツールをほぼ使わず書かれているのも特徴的です。

ただし、実装のハードルは低くないです。コメントにあった指摘：「GPUのVRAMが80GB未満なら、ハイパーパラメータを調整しないとOOMで落ちる」。バッチサイズやメモリ効率のチューニングが必要で、初心者がそのまま動かせるわけではなさそうです。

特定ドメインのドキュメントでファインチューニングする用途には使えるかもしれません。ある開発者は「specific questionsに特化させる」アプローチを提案していました。

## 本番環境で使えるレベルか

正直、本番投入は厳しいでしょう。

561Mパラメータは軽量で推論コストが低いメリットはありますが、精度は商用LLMに遠く及びません。$100で訓練した結果は「幼稚園児レベル」で、実用的な回答精度を求めるなら$1000（42時間訓練）は必要です。それでも簡単な数学・コーディング問題が解ける程度で、GPT-4やClaude 3.5には遠く及びません。

既存システムへの組み込みコストも気になります。Web UI付きとはいえ、APIエンドポイントの設計、スケーリング、エラーハンドリングは自前実装です。プロダクション運用のノウハウがないと、結局OpenAI APIを使った方が速いです。

## 個人的に気になった点

教育目的としては面白いプロジェクトだと思います。

前にLLMの推論最適化を試したときに、メモリ効率とレイテンシのトレードオフで詰まった経験があります。nanochatがどうバランスを取っているか、コードを読んでみたいです。特にKV cacheの管理周りは参考になりそうです。

ただ、$100で実用的なモデルができるかと言われると懐疑的です。商用利用を考えるなら、素直にOpenAI/Anthropic APIを使った方がコスト・精度ともに優位です。独自データでの訓練が必要なケースでも、LoRAやRAGで十分なことが多いです。

とはいえ、LLM訓練の全体像を8000行のコードで学べるのは価値があります。Eureka LabsのLLM101nコースが公開されたら、nanochatをベースに訓練パイプラインを理解する良い機会になりそうです。業界的にはLLMのコモディティ化が進んでいる流れで、こういう教育リソースが増えるのは歓迎です。
